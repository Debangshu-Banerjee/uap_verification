{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.util import get_net\n",
    "import src.config as c\n",
    "from src.common.network import LayerType\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, transform = None):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "    def __iter__(self):\n",
    "        if self.transform is None:\n",
    "            for b in self.dl:\n",
    "                yield to_device(b, self.device)\n",
    "        else:\n",
    "            for b in self.dl:\n",
    "                a = to_device(b, self.device)\n",
    "                yield [self.transform(a[0]), a[0], a[1]]\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "def toDeviceDataLoader(*args, device = torch.device('cuda:0'), batch_size = 16, transform = None):\n",
    "    dls = [torch.utils.data.DataLoader(d, batch_size = batch_size, shuffle = True, drop_last = True) for d in args]\n",
    "    return [DeviceDataLoader(d, device = device, transform = transform) for d in dls]\n",
    "\n",
    "def load_mnist(batch_size_train, batch_size_test, device, dataset_path=\"/share/datasets/mnist/\", normalize = True):\n",
    "    if normalize:\n",
    "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    else:\n",
    "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0,), (1,))])\n",
    "    train_dataset = torchvision.datasets.MNIST(dataset_path, download=True, train=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.MNIST(dataset_path, download=True, train=False, transform=transform)\n",
    "    train_loader = toDeviceDataLoader(train_dataset, device = device, batch_size = batch_size_train)[0]\n",
    "    test_loader = toDeviceDataLoader(test_dataset, device = device, batch_size = batch_size_test)[0]\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def dsa_01(ds, k, verbose = False):\n",
    "    tot = 0\n",
    "    acc = 0\n",
    "    for batch in ds:\n",
    "        out = k(batch[0])\n",
    "        acc += accuracy(out, batch[1]) * len(batch[1])\n",
    "        tot += len(batch[1])\n",
    "    if verbose:\n",
    "        print(acc, tot)\n",
    "    return (acc/tot).item()\n",
    "\n",
    "mnist_train_loader_n, mnist_test_loader_n = load_mnist(64, 128, device, normalize = True)\n",
    "mnist_train_loader, mnist_test_loader = load_mnist(64, 128, device, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 10, 20, 20])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Conv2d(10, 15, 20, padding=2).weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load(f'src/nets/{c.MNIST_CONV_SMALL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "stride",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mnode:\n\u001b[0;32m----> 2\u001b[0m   \u001b[39mprint\u001b[39m(node\u001b[39m.\u001b[39;49mstride)\n",
      "\u001b[0;31mAttributeError\u001b[0m: stride"
     ]
    }
   ],
   "source": [
    "for node in model.graph.node:\n",
    "  print(node.stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_net(net, dataset, normalize = True):\n",
    "    layers = get_net(f'src/nets/{net}', dataset)\n",
    "    modules = []\n",
    "    seen_linear = False\n",
    "    for layer in layers:\n",
    "        if layer.type == LayerType.Conv2D:\n",
    "            modules.append(torch.nn.Conv2d(layer.weight.shape[1], layer.weight.shape[0], layer.weight.shape[2], stride = 2, padding=0))\n",
    "            modules[-1].weight = torch.nn.Parameter(layer.weight)\n",
    "            modules[-1].bias = torch.nn.Parameter(layer.bias)\n",
    "        elif layer.type == LayerType.Linear:\n",
    "            if not seen_linear:\n",
    "                seen_linear = True\n",
    "                modules.append(torch.nn.Flatten())\n",
    "            modules.append(torch.nn.Linear(layer.weight.shape[1], layer.weight.shape[0]))\n",
    "            modules[-1].weight = torch.nn.Parameter(layer.weight)\n",
    "            modules[-1].bias = torch.nn.Parameter(layer.bias)\n",
    "        elif layer.type == LayerType.ReLU: \n",
    "            modules.append(torch.nn.ReLU())\n",
    "        elif layer.type == LayerType.Flatten:\n",
    "            modules.append(torch.nn.Flatten())\n",
    "        else:\n",
    "            raise ValueError(f'Layer type {layer.type} not supported')\n",
    "    model = nn.Sequential(*modules)\n",
    "    model.eval().to(device)\n",
    "    #print(model)\n",
    "\n",
    "    if dataset == 'cifar':\n",
    "        print(f\"{net}: {dsa_01(dataset, model)}\")\n",
    "    else:\n",
    "        if normalize:\n",
    "            print(f\"{net}: {dsa_01(mnist_test_loader_n, model)}\")\n",
    "        else:\n",
    "            print(f\"{net}: {dsa_01(mnist_test_loader, model)}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization ((0.1307,), (0.3081,))\n",
      "mnist_relu_3_50.onnx: 0.938401460647583\n",
      "mnist_relu_3_100.onnx: 0.9385015964508057\n",
      "mnist_convSmallRELU__Point.onnx: 0.9824719429016113\n",
      "mnistconvSmallRELU__PGDK.onnx: 0.989182710647583\n",
      "mnistconvSmallRELUDiffAI.onnx: 0.9773637652397156\n",
      "Normalization ((0,), (1,))\n",
      "mnist_relu_3_50.onnx: 0.9588341116905212\n",
      "mnist_relu_3_100.onnx: 0.9654446840286255\n",
      "mnist_convSmallRELU__Point.onnx: 0.9803686141967773\n",
      "mnistconvSmallRELU__PGDK.onnx: 0.9887820482254028\n",
      "mnistconvSmallRELUDiffAI.onnx: 0.9536257982254028\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalization ((0.1307,), (0.3081,))\")\n",
    "evaluate_net(c.MNIST_LINEAR_50, 'mnist', normalize = True)\n",
    "evaluate_net(c.MNIST_LINEAR_100, 'mnist', normalize = True)\n",
    "evaluate_net(c.MNIST_CONV_SMALL, 'mnist', normalize = True)\n",
    "#evaluate_net(c.MNIST_CONV_MED, 'mnist', normalize = True)\n",
    "evaluate_net(c.MNIST_FFN_PGD, 'mnist', normalize = True)\n",
    "evaluate_net(c.MNIST_FFN_DIFFAI, 'mnist', normalize = True)\n",
    "print(\"Normalization ((0,), (1,))\")\n",
    "evaluate_net(c.MNIST_LINEAR_50, 'mnist', normalize = False)\n",
    "evaluate_net(c.MNIST_LINEAR_100, 'mnist', normalize = False)\n",
    "evaluate_net(c.MNIST_CONV_SMALL, 'mnist', normalize = False)\n",
    "#evaluate_net(c.MNIST_CONV_MED, 'mnist', normalize = False)\n",
    "evaluate_net(c.MNIST_FFN_PGD, 'mnist', normalize = False)\n",
    "evaluate_net(c.MNIST_FFN_DIFFAI, 'mnist', normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_relu_3_50.onnx: 0.9587339758872986\n",
      "mnist_relu_3_100.onnx: 0.9654446840286255\n",
      "mnist_convSmallRELU__Point.onnx: 0.9803686141967773\n",
      "mnistconvSmallRELU__PGDK.onnx: 0.9888821840286255\n",
      "mnistconvSmallRELUDiffAI.onnx: 0.9535256624221802\n"
     ]
    }
   ],
   "source": [
    "evaluate_net(c.MNIST_LINEAR_50, 'mnist', normalize = False)\n",
    "evaluate_net(c.MNIST_LINEAR_100, 'mnist', normalize = False)\n",
    "evaluate_net(c.MNIST_CONV_SMALL, 'mnist', normalize = False)\n",
    "#evaluate_net(c.MNIST_CONV_MED, 'mnist', normalize = False)\n",
    "evaluate_net(c.MNIST_FFN_PGD, 'mnist', normalize = False)\n",
    "evaluate_net(c.MNIST_FFN_DIFFAI, 'mnist', normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uapv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
